{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City Shadows: Google Street View Image Extraction\n",
    "This notebook automates the collection of Google Street View images using the GSV API\n",
    "\n",
    "### Requirements:\n",
    "- .env file containing a **Google Street View** (https://developers.google.com/maps/documentation/streetview) API key (GSV_API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import shapely\n",
    "import urllib, os\n",
    "import random\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading shape files\n",
    "shape - obtained from Geofabrik. contains all available road data in the country\n",
    "small_makati - obtained from LiPAD (https://lipad.dream.upd.edu.ph/shapefilegen.html). geofabrik may have shapefiles of administrative areas for your respective country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=gpd.read_file(\"..\\data\\gis_osm_roads_free_1.shp\")\n",
    "makati = gpd.read_file(\"..\\data\\makati_city.shp\")\n",
    "small_makati = gpd.read_file(\"..\\data\\smaller_makati.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL: Remove areas without any GSV info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urdaneta = gpd.read_file(\"..\\\\data\\\\urdaneta.shp\")\n",
    "lower_makati = gpd.read_file(\"..\\\\data\\\\lower_makati.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_gsv = shapely.difference(small_makati, urdaneta)\n",
    "only_gsv = shapely.difference(only_gsv, lower_makati)\n",
    "# for viewing\n",
    "only_gsv.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts all the streets that are contained in the smaller administrative area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makati_streets = shape[makati['geometry'].item().contains(shape['geometry'])]\n",
    "less_makati_streets = shape[small_makati['geometry'].item().contains(shape['geometry'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_makati_streets[0:850].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost calculation<br>\n",
    "Run this block if you wanna check how many points will be captured "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "FIFTY_METERS = 0.0000449 * 10\n",
    "ANGLE_COUNT = 8\n",
    "for street in less_makati_streets[250:850]['geometry'].items():\n",
    "    sum += math.ceil(street[1].length/FIFTY_METERS)\n",
    "required = sum * ANGLE_COUNT \n",
    "required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PER_1000_IMAGE = 7\n",
    "USD_TO_PHP = 55\n",
    "required / 1000 * PER_1000_IMAGE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angles to record, API key, and output folder location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = []\n",
    "interval = 45\n",
    "for i in range (0, 360, interval):\n",
    "   angle.append(i)\n",
    "load_dotenv(override=True)\n",
    "GSV_API = os.getenv('GSV_API')\n",
    "key = \"&key=\" + GSV_API  \n",
    "myloc = \"..\\out\"         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading already processed pano_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pano_ids = []\n",
    "\n",
    "if os.path.exists(\"pano_ids.txt\"):\n",
    "    with open(\"pano_ids.txt\", \"r\") as f:\n",
    "        processed_pano_ids = [line.strip() for line in f]\n",
    "\n",
    "print(f\"Loaded {len(processed_pano_ids)} pano_ids from pano_ids.txt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading already processed coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_lat_long = []\n",
    "\n",
    "if os.path.exists(\"lat_long.txt\"):\n",
    "    with open(\"lat_long.txt\", \"r\") as f:\n",
    "        processed_lat_long = [line.strip() for line in f]\n",
    "\n",
    "print(f\"Loaded {len(processed_lat_long)} latlong pairs from lat_long.txt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleepRandom():\n",
    "   time.sleep(random.randrange(5,7))\n",
    "\n",
    "\n",
    "def getGSVMetadata(lat,long):\n",
    "  sleepRandom()\n",
    "  metaURL = \"https://maps.googleapis.com/maps/api/streetview/metadata?location=\" + str(lat) + \",\" + str(long) + key\n",
    "  urllib.request.urlretrieve(metaURL)\n",
    "  response = requests.get(metaURL)\n",
    "\n",
    "  # check json response for status and pano_id\n",
    "  if response.status_code == 200:\n",
    "      data = response.json()\n",
    "      pano_id = data.get(\"pano_id\")\n",
    "      status = data.get(\"status\")\n",
    "\n",
    "      if pano_id in processed_pano_ids:\n",
    "        return \"DUPLICATE\"\n",
    "\n",
    "      if status == \"OK\":\n",
    "        return pano_id\n",
    "      else:\n",
    "        if(str(lat) + \",\" + str(long)) not in processed_lat_long:       # check if lat,long is already processed\n",
    "          processed_lat_long.append(str(lat) + \",\" + str(long))         # append lat,long to processed latlong list\n",
    "          with open(\"lat_long.txt\", \"a\") as f:                          # append lat,long to .txt file\n",
    "              f.write(f\"{str(lat) + \",\" + str(long)}\\n\")\n",
    "        return \"NO IMAGE\"\n",
    "\n",
    "  else:\n",
    "      print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "def getStreet(add,outputLocation, angles):\n",
    "  base = \"https://maps.googleapis.com/maps/api/streetview?size=640x640&fov=120&source=outdoor&pitch=20&location=\"\n",
    "  coor = add\n",
    "\n",
    "  # loop through angles declared\n",
    "\n",
    "  for angle in angles:\n",
    "    sleepRandom()\n",
    "    heading = \"&heading=\" + str(angle)    \n",
    "    finalURL = base + coor + heading + key\n",
    "    fi = add + \"_\" + str(angle) + \".jpg\"\n",
    "    urllib.request.urlretrieve(finalURL, os.path.join(outputLocation,fi))\n",
    "  \n",
    "def getEquidistantPoints(pathLength, x, y):\n",
    "  # Linear length on the line; euclidean distance\n",
    "  distance = np.cumsum(np.sqrt( np.ediff1d(x, to_begin=0)**2 + np.ediff1d(y, to_begin=0)**2 ))\n",
    "  distance = distance/distance[-1]\n",
    "\n",
    "  fx, fy = interp1d( distance, x ), interp1d( distance, y )\n",
    "\n",
    "  count = math.ceil(pathLength/FIFTY_METERS)\n",
    "  alpha = np.linspace(0, 1, count)\n",
    "  xPoint, yPoint = fx(alpha), fy(alpha)\n",
    "\n",
    "  return xPoint, yPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_lat_long = []\n",
    "\n",
    "if os.path.exists(\"lat_long.txt\"):\n",
    "    with open(\"lat_long.txt\", \"r\") as f:\n",
    "        processed_lat_long = [line.strip() for line in f]\n",
    "\n",
    "print(f\"Loaded {len(processed_lat_long)} latlong pairs from lat_long.txt.\")\n",
    "\n",
    "for row in less_makati_streets[250:850]['geometry'].items():\n",
    "    print(f\"Searching road {row[0]}.\")\n",
    "    x = row[1].coords.xy[1]\n",
    "    y = row[1].coords.xy[0]\n",
    "    length = row[1].length\n",
    "    equiXPoints, equiYPoints = getEquidistantPoints(length, x, y)\n",
    "    # TOO SCARED TO RUN THIS LOL\n",
    "    for i in range(0, len(equiXPoints)):\n",
    "      if \"('\" + str(equiXPoints[i]) +\"', '\"+ str(equiYPoints[i]) + \"')\" not in processed_lat_long:\n",
    "        latlong = str(equiXPoints[i]) + \",\" + str(equiYPoints[i]) \n",
    "        print(latlong + \" unprocessed.\")\n",
    "        status = getGSVMetadata(equiXPoints[i], equiYPoints[i])\n",
    "        if status == 'DUPLICATE':\n",
    "          print(str(equiXPoints[i]) + \",\" + str(equiYPoints[i]) + \"'s pano_id has already been processed.\")\n",
    "          processed_lat_long.append(f\"('{equiXPoints[i]}', '{equiYPoints[i]}')\")\n",
    "          with open(\"lat_long.txt\", \"a\") as f:      # append latlong to .txt file\n",
    "            f.write(f\"('{equiXPoints[i]}', '{equiYPoints[i]}')\\n\")\n",
    "        elif \"NO IMAGE\" in status:\n",
    "          print(f\"{equiXPoints[i]},{equiYPoints[i]} No image found.\")\n",
    "          processed_lat_long.append(f\"('{equiXPoints[i]}', '{equiYPoints[i]}')\")\n",
    "          with open(\"lat_long.txt\", \"a\") as f:      # append latlong to .txt file\n",
    "            f.write(f\"('{equiXPoints[i]}', '{equiYPoints[i]}')\\n\")\n",
    "        else :\n",
    "          latlong = str(equiXPoints[i]) + \",\" + str(equiYPoints[i]) \n",
    "          getStreet(add=latlong,outputLocation=myloc, angles=angle)\n",
    "          print(latlong + \" image found.\")\n",
    "          processed_pano_ids.append(status)         # append pano_id to processed pano list\n",
    "          with open(\"pano_ids.txt\", \"a\") as f:      # append pano_id to .txt file\n",
    "            f.write(f\"{status}\\n\")\n",
    "          processed_lat_long.append(f\"('{equiXPoints[i]}', '{equiYPoints[i]}')\")\n",
    "          with open(\"lat_long.txt\", \"a\") as f:      # append latlong to .txt file\n",
    "            f.write(f\"('{equiXPoints[i]}', '{equiYPoints[i]}')\\n\")\n",
    "            \n",
    "      else:\n",
    "         latlong = str(equiXPoints[i]) + \",\" + str(equiYPoints[i]) \n",
    "        #  print(f\"{latlong} has already been processed.\" )\n",
    "\n",
    "print(\"end.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
